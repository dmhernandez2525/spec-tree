# Software Design Document: Multi-Provider AI Backend

## Metadata

| Field | Value |
|-------|-------|
| **Feature ID** | F1.1.9 |
| **Status** | Ready |
| **Created** | 2026-01-17 |
| **Last Updated** | 2026-01-17 |
| **Author** | Daniel Hernandez |
| **Assignee** | TBD |
| **Branch** | `feat/F1.1.9-multi-provider-ai-backend` |
| **PR** | N/A |
| **Phase** | 1 |
| **Priority** | P1 |
| **Estimated Effort** | 8 days |

---

## 1. Overview

### 1.1 Brief Description
Complete the backend integration for Claude (Anthropic) and Gemini (Google) AI providers, enabling users to choose their preferred provider for AI generation. The provider abstraction layer has been scaffolded; this feature completes the implementation and adds provider fallback, model discovery, and unified response handling.

### 1.2 Business Value
- **Provider flexibility**: Users can choose based on cost, quality, or preference
- **Competitive advantage**: Few tools offer true multi-provider support
- **Risk mitigation**: Fallback to alternative providers during outages
- **Cost optimization**: Users can select cheaper models for simple tasks
- **Future-proofing**: Easy to add new providers as they emerge

### 1.3 Success Metrics
- All three providers (OpenAI, Claude, Gemini) successfully generate work items
- Provider switching works without page refresh
- Fallback triggers within 5 seconds of primary provider failure
- Token usage tracked accurately across all providers

---

## 2. User Story

**As a** Spec Tree user,
**I want** to choose between OpenAI, Claude, and Gemini for AI generation,
**So that** I can use my preferred provider or take advantage of different model capabilities and pricing.

### 2.1 User Personas Affected
- [x] Product Manager
- [x] Developer
- [x] Tech Lead
- [ ] Designer
- [ ] Stakeholder
- [x] Admin

---

## 3. Acceptance Criteria

### 3.1 Functional Requirements

- [ ] **AC-1:** Claude API integration generates work items correctly
- [ ] **AC-2:** Gemini API integration generates work items correctly
- [ ] **AC-3:** User can select provider in AI settings
- [ ] **AC-4:** User can select specific model within provider
- [ ] **AC-5:** Provider selection persists per user/organization
- [ ] **AC-6:** Graceful fallback to alternative provider on failure
- [ ] **AC-7:** All existing prompt templates work across all providers
- [ ] **AC-8:** Response parsing handles provider-specific formats
- [ ] **AC-9:** API key validation for each provider before use
- [ ] **AC-10:** Cost tracking works for all providers with correct pricing
- [ ] **AC-11:** Rate limit handling per provider with appropriate retries
- [ ] **AC-12:** User can configure fallback order

### 3.2 Non-Functional Requirements

- [ ] **NFR-1:** Performance - Provider switch completes in <1 second
- [ ] **NFR-2:** Reliability - Fallback triggers within 5 seconds of failure
- [ ] **NFR-3:** Security - API keys stored securely, never logged
- [ ] **NFR-4:** Monitoring - Provider usage logged for debugging

### 3.3 Edge Cases

- [ ] **EC-1:** User has no API key for selected provider - Prompt to configure
- [ ] **EC-2:** All providers fail - Show clear error with retry option
- [ ] **EC-3:** Model deprecated by provider - Fall back to default model
- [ ] **EC-4:** Rate limit hit - Queue requests with exponential backoff

---

## 4. Technical Design

### 4.1 Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Multi-Provider Architecture                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Client Request                                                         â”‚
â”‚         â”‚                                                               â”‚
â”‚         â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                   â”‚
â”‚  â”‚ AI Router       â”‚ â”€â”€â”€ Selects provider based on user preference     â”‚
â”‚  â”‚ Service         â”‚     and availability                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
â”‚           â”‚                                                            â”‚
â”‚           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚           â–¼                â–¼                â–¼                â–¼        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ OpenAI      â”‚  â”‚ Claude      â”‚  â”‚ Gemini      â”‚  â”‚ Future      â”‚  â”‚
â”‚  â”‚ Provider    â”‚  â”‚ Provider    â”‚  â”‚ Provider    â”‚  â”‚ Provider    â”‚  â”‚
â”‚  â”‚ âœ… Complete â”‚  â”‚ ðŸ”„ Scaffoldâ”‚  â”‚ ðŸ”„ Scaffoldâ”‚  â”‚ ðŸ“‹ Planned  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                â”‚                â”‚                            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                          â”‚                                              â”‚
â”‚                          â–¼                                              â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚                 â”‚ Unified Responseâ”‚                                    â”‚
â”‚                 â”‚ Format          â”‚                                    â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                          â”‚                                              â”‚
â”‚                          â–¼                                              â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚                 â”‚ Client Response â”‚                                    â”‚
â”‚                 â”‚ (consistent)    â”‚                                    â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Data Models

```typescript
// Provider configuration
enum AIProvider {
  OPENAI = 'openai',
  ANTHROPIC = 'anthropic',
  GOOGLE = 'google',
}

interface ProviderConfig {
  provider: AIProvider;
  apiKey: string;
  defaultModel: string;
  enabled: boolean;
  priority: number; // For fallback order
}

interface ModelInfo {
  id: string;
  provider: AIProvider;
  displayName: string;
  contextWindow: number;
  inputPrice: number;  // per 1M tokens
  outputPrice: number; // per 1M tokens
  capabilities: ModelCapability[];
}

type ModelCapability = 'text' | 'vision' | 'code' | 'reasoning';

// Request/Response interfaces
interface AIRequest {
  systemPrompt: string;
  userPrompt: string;
  provider?: AIProvider;
  model?: string;
  maxTokens?: number;
  temperature?: number;
}

interface AIResponse {
  content: string;
  provider: AIProvider;
  model: string;
  usage: {
    inputTokens: number;
    outputTokens: number;
    totalTokens: number;
  };
  cost: number;
  latency: number;
}

// Provider interface (implemented by each provider)
interface AIProviderInterface {
  name: AIProvider;
  generateCompletion(request: ProviderRequest): Promise<ProviderResponse>;
  validateApiKey(key: string): Promise<boolean>;
  listModels(): Promise<ModelInfo[]>;
  getDefaultModel(): string;
}

interface ProviderRequest {
  messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }>;
  model: string;
  maxTokens: number;
  temperature: number;
}

interface ProviderResponse {
  content: string;
  usage: {
    inputTokens: number;
    outputTokens: number;
  };
  model: string;
  finishReason: 'stop' | 'length' | 'error';
}

// Fallback configuration
interface FallbackConfig {
  enabled: boolean;
  maxRetries: number;
  retryDelay: number;
  providerOrder: AIProvider[];
}

// Cost tracking
interface UsageRecord {
  timestamp: Date;
  provider: AIProvider;
  model: string;
  inputTokens: number;
  outputTokens: number;
  cost: number;
  operation: 'epic' | 'feature' | 'story' | 'task' | 'questions';
  userId: string;
  appId: string;
}
```

### 4.3 API Endpoints

| Method | Endpoint | Purpose | Request | Response |
|--------|----------|---------|---------|----------|
| POST | `/api/ai/completion` | Generate AI completion | `AIRequest` | `AIResponse` |
| GET | `/api/ai/providers` | List available providers | - | `ProviderConfig[]` |
| GET | `/api/ai/models/:provider` | List models for provider | - | `ModelInfo[]` |
| POST | `/api/ai/validate-key` | Validate API key | `{provider, key}` | `{valid: boolean}` |
| GET | `/api/ai/usage` | Get usage statistics | - | `UsageRecord[]` |

### 4.4 State Management

```typescript
// AI settings state (client-side)
interface AIState {
  selectedProvider: AIProvider;
  selectedModel: string;
  providers: {
    [key in AIProvider]: {
      apiKey: string;
      enabled: boolean;
      models: ModelInfo[];
    };
  };
  fallback: FallbackConfig;
  usage: {
    currentPeriod: UsageRecord[];
    totalCost: number;
  };
}

// Redux slice actions
const aiSlice = createSlice({
  name: 'ai',
  initialState,
  reducers: {
    setProvider: (state, action: PayloadAction<AIProvider>) => {},
    setModel: (state, action: PayloadAction<string>) => {},
    setApiKey: (state, action: PayloadAction<{provider: AIProvider; key: string}>) => {},
    setFallbackConfig: (state, action: PayloadAction<FallbackConfig>) => {},
    addUsageRecord: (state, action: PayloadAction<UsageRecord>) => {},
  },
});
```

### 4.5 Provider Implementations

#### OpenAI Provider (Complete)
```typescript
// Microservice/src/services/providers/openai.provider.ts
export class OpenAIProvider implements AIProviderInterface {
  name = AIProvider.OPENAI;

  async generateCompletion(request: ProviderRequest): Promise<ProviderResponse> {
    const response = await openai.chat.completions.create({
      model: request.model,
      messages: request.messages,
      max_tokens: request.maxTokens,
      temperature: request.temperature,
    });

    return {
      content: response.choices[0].message.content,
      usage: {
        inputTokens: response.usage.prompt_tokens,
        outputTokens: response.usage.completion_tokens,
      },
      model: response.model,
      finishReason: response.choices[0].finish_reason,
    };
  }
}
```

#### Claude Provider (To Implement)
```typescript
// Microservice/src/services/providers/anthropic.provider.ts
export class AnthropicProvider implements AIProviderInterface {
  name = AIProvider.ANTHROPIC;

  async generateCompletion(request: ProviderRequest): Promise<ProviderResponse> {
    const response = await anthropic.messages.create({
      model: request.model,
      max_tokens: request.maxTokens,
      system: request.messages.find(m => m.role === 'system')?.content,
      messages: request.messages
        .filter(m => m.role !== 'system')
        .map(m => ({ role: m.role, content: m.content })),
    });

    return {
      content: response.content[0].text,
      usage: {
        inputTokens: response.usage.input_tokens,
        outputTokens: response.usage.output_tokens,
      },
      model: response.model,
      finishReason: response.stop_reason === 'end_turn' ? 'stop' : 'length',
    };
  }
}
```

#### Gemini Provider (To Implement)
```typescript
// Microservice/src/services/providers/gemini.provider.ts
export class GeminiProvider implements AIProviderInterface {
  name = AIProvider.GOOGLE;

  async generateCompletion(request: ProviderRequest): Promise<ProviderResponse> {
    const model = genAI.getGenerativeModel({ model: request.model });

    const chat = model.startChat({
      history: request.messages.slice(0, -1).map(m => ({
        role: m.role === 'user' ? 'user' : 'model',
        parts: [{ text: m.content }],
      })),
    });

    const result = await chat.sendMessage(
      request.messages[request.messages.length - 1].content
    );

    return {
      content: result.response.text(),
      usage: {
        inputTokens: result.response.usageMetadata.promptTokenCount,
        outputTokens: result.response.usageMetadata.candidatesTokenCount,
      },
      model: request.model,
      finishReason: 'stop',
    };
  }
}
```

### 4.6 Implementation Steps

1. [ ] Complete AnthropicProvider implementation
2. [ ] Complete GeminiProvider implementation
3. [ ] Implement AIRouter service with fallback logic
4. [ ] Add API key validation endpoints
5. [ ] Add model listing endpoints
6. [ ] Update client API calls to use new unified endpoint
7. [ ] Update AI settings UI to show all providers
8. [ ] Implement provider-specific prompt adjustments
9. [ ] Add usage tracking and cost calculation
10. [ ] Add fallback configuration UI
11. [ ] Write comprehensive tests for all providers
12. [ ] Performance testing with all providers

---

## 5. Files Affected

### 5.1 New Files

| File Path | Purpose |
|-----------|---------|
| `Microservice/src/services/ai-router.service.ts` | Route requests to appropriate provider |
| `Microservice/src/services/providers/anthropic.provider.ts` | Claude implementation |
| `Microservice/src/services/providers/gemini.provider.ts` | Gemini implementation |
| `Microservice/src/services/providers/base.provider.ts` | Base provider interface |
| `Microservice/src/routes/ai.routes.ts` | New unified AI routes |
| `Microservice/src/middleware/ai-rate-limit.ts` | Provider-specific rate limiting |
| `Microservice/src/utils/cost-calculator.ts` | Calculate costs per provider |
| `Client/lib/store/ai-slice.ts` | AI state management |

### 5.2 Modified Files

| File Path | Changes |
|-----------|---------|
| `Microservice/src/services/providers/openai.provider.ts` | Implement interface |
| `Microservice/src/index.ts` | Add new routes |
| `Client/components/spec-tree/lib/api/openai.ts` | Update to use unified endpoint |
| `Client/components/dashboard/organization/settings/AISettings.tsx` | Add provider selection |
| `Client/lib/store/index.ts` | Add AI slice |

---

## 6. Testing Strategy

### 6.1 Unit Tests

| Test | Description | File |
|------|-------------|------|
| `OpenAIProvider` | Test completion generation | `openai.provider.test.ts` |
| `AnthropicProvider` | Test completion generation | `anthropic.provider.test.ts` |
| `GeminiProvider` | Test completion generation | `gemini.provider.test.ts` |
| `AIRouter` | Test provider selection and fallback | `ai-router.test.ts` |
| `CostCalculator` | Test cost calculation accuracy | `cost-calculator.test.ts` |

### 6.2 Integration Tests

| Test | Description | File |
|------|-------------|------|
| `ProviderFallback` | Test fallback when primary fails | `provider-fallback.test.ts` |
| `KeyValidation` | Test API key validation for all providers | `key-validation.test.ts` |
| `EndToEndGeneration` | Test full generation flow | `generation.integration.test.ts` |

### 6.3 E2E Tests

| Test | Description | File |
|------|-------------|------|
| `provider-switch` | Test switching providers in UI | `provider-switch.spec.ts` |
| `generation-all-providers` | Test generation with each provider | `generation.spec.ts` |

### 6.4 Manual Testing Checklist

- [ ] Generate epics with OpenAI
- [ ] Generate epics with Claude
- [ ] Generate epics with Gemini
- [ ] Switch provider mid-session
- [ ] Verify cost tracking accuracy
- [ ] Test fallback when provider is down (mock)
- [ ] Test rate limit handling
- [ ] Verify API key validation

---

## 7. Dependencies

### 7.1 Depends On

| Feature ID | Name | Status |
|------------|------|--------|
| - | OpenAI provider | Complete |
| - | AI Settings UI | Complete |

### 7.2 Blocks

| Feature ID | Name |
|------------|------|
| F1.1.10 | Streaming AI responses |
| F1.3.6 | Claude provider stability |
| F1.3.7 | Gemini provider stability |

### 7.3 External Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| `@anthropic-ai/sdk` | `^0.25.0` | Claude API client |
| `@google/generative-ai` | `^0.16.0` | Gemini API client |
| `openai` | `^4.24.1` | OpenAI API client (existing) |

---

## 8. Risks & Mitigations

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Provider API changes | Medium | High | Pin SDK versions, monitor changelogs |
| Response format differences | High | Medium | Unified response parsing layer |
| Rate limits vary by provider | High | Medium | Per-provider rate limit config |
| Cost miscalculation | Medium | Medium | Regular price verification, alerts |
| API key security | Low | High | Encrypt at rest, never log keys |

---

## 9. Rollout Plan

### 9.1 Feature Flag
- Flag name: `feature_multi_provider`
- Default: `false` during development
- Enable for: Beta users first, then general availability

### 9.2 Rollout Phases
1. **Internal testing**: 1 week
2. **Beta users**: 1 week with Claude only
3. **Add Gemini**: After Claude stable
4. **General availability**: After both stable

---

## 10. Definition of Done

- [ ] All acceptance criteria met
- [ ] All three providers generate work items correctly
- [ ] Fallback logic works reliably
- [ ] Cost tracking accurate within 1%
- [ ] All tests passing (unit, integration, E2E)
- [ ] Code reviewed and approved
- [ ] Documentation updated
- [ ] No TypeScript errors
- [ ] No ESLint warnings
- [ ] Performance acceptable (<3s generation)
- [ ] Security review passed (API key handling)
- [ ] PR merged to main

---

## 11. References

- [OpenAI API Documentation](https://platform.openai.com/docs/)
- [Anthropic API Documentation](https://docs.anthropic.com/)
- [Google AI Studio Documentation](https://ai.google.dev/docs)
- Existing provider abstraction in `Microservice/src/services/providers/`
- AI Settings UI in `Client/components/dashboard/organization/settings/AISettings.tsx`

---

## 12. Changelog

| Date | Author | Change |
|------|--------|--------|
| 2026-01-17 | Daniel Hernandez | Initial draft |

---

## Model Pricing Reference (January 2026)

### OpenAI

| Model | Input/1M | Output/1M | Context |
|-------|----------|-----------|---------|
| gpt-4o | $2.50 | $10.00 | 128K |
| gpt-4o-mini | $0.15 | $0.60 | 128K |
| gpt-4-turbo | $10.00 | $30.00 | 128K |

### Anthropic

| Model | Input/1M | Output/1M | Context |
|-------|----------|-----------|---------|
| claude-3-5-sonnet | $3.00 | $15.00 | 200K |
| claude-3-5-haiku | $1.00 | $5.00 | 200K |
| claude-3-opus | $15.00 | $75.00 | 200K |

### Google

| Model | Input/1M | Output/1M | Context |
|-------|----------|-----------|---------|
| gemini-2.5-pro | $1.25 | $10.00 | 1M+ |
| gemini-2.5-flash | $0.50 | $3.00 | 1M |
| gemini-1.5-pro | $1.25 | $5.00 | 1M |

---

## AI Agent Export Format

<details>
<summary>Click to expand AI-ready specification</summary>

```json
{
  "specVersion": "1.0",
  "generatedBy": "SpecTree",
  "feature": {
    "id": "F1.1.9",
    "title": "Multi-Provider AI Backend",
    "type": "backend",
    "context": {
      "project": "Spec Tree",
      "phase": 1,
      "techStack": ["Express.js", "TypeScript", "OpenAI SDK", "Anthropic SDK", "Google AI SDK"],
      "existingPatterns": "Microservice/src/services/providers/"
    },
    "specification": {
      "userStory": "As a user, I want to choose between OpenAI, Claude, and Gemini for AI generation.",
      "acceptanceCriteria": [
        "Claude API integration working",
        "Gemini API integration working",
        "Provider selection persists",
        "Graceful fallback on failure",
        "Cost tracking for all providers",
        "Response parsing handles all formats"
      ],
      "filesAffected": [
        "Microservice/src/services/ai-router.service.ts",
        "Microservice/src/services/providers/anthropic.provider.ts",
        "Microservice/src/services/providers/gemini.provider.ts",
        "Microservice/src/routes/ai.routes.ts"
      ],
      "testRequirements": [
        "Unit tests for each provider",
        "Integration tests for fallback",
        "E2E tests for provider switching"
      ]
    },
    "constraints": {
      "mustUse": ["Official provider SDKs", "Unified response format"],
      "mustNotUse": ["Direct HTTP calls to providers"],
      "performanceTarget": "Generation in <3 seconds"
    }
  }
}
```

</details>
